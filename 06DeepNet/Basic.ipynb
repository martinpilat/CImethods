{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Tutorial - Basics #\n",
    "###  Štěpán Procházka, April 2019\n",
    "\n",
    "This notebook is written in Python3 and to run it, install following dependencies (preferably in virtual environment).\n",
    "\n",
    "```\n",
    "# create and activate virtual environment\n",
    "$ python3 -m venv env\n",
    "$ . env/bin/activate\n",
    "\n",
    "# install dependencies\n",
    "$ pip install numpy matplotlib scipy tqdm tensorflow  # or tensorflow-gpu\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to effectively disable dedicated GPU (if present)\n",
    "%env CUDA_VISIBLE_DEVICES=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToC ##\n",
    "1. Tensorflow basics\n",
    "    - Installation\n",
    "    - [`Hello, World!`](#Hello%2C-World!-in-TF)\n",
    "    - [`Hello, ML!`](#Hello%2C-ML!)\n",
    "    - [TensorFlow, Graph, Operation, Tensor, Session](#TF-basic-concepts)\n",
    "    - [kNN classifier](#kNN-classifier)\n",
    "    - [Variables](#tf.Variable)\n",
    "    \n",
    "----\n",
    "## How to install ##\n",
    "\n",
    "```sh\n",
    "$ python3 -m venv env\n",
    "$ . env/bin/activate\n",
    "\n",
    "$ pip install tensorflow\n",
    "# alternatively (needs nvidia driver, CUDA and cuDNN installation)\n",
    "$ pip install tensorflow-gpu\n",
    "```\n",
    "\n",
    "----\n",
    "## Hello, World! in TF##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(6)\n",
    "b = tf.constant(7)\n",
    "\n",
    "# result = a * b\n",
    "c = tf.multiply(a, b)\n",
    "\n",
    "with tf.Session():\n",
    "    result = c.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Hello, ML! ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "fig, (ax_im, ax_pred) = plt.subplots(ncols=2, figsize=(8.5, 4))\n",
    "fig.set_label('MNIST Classifier')\n",
    "\n",
    "def show_example(i, is_train=True):\n",
    "    ax_im.clear()\n",
    "    x, y = (x_train[i], y_train[i]) if is_train else (x_test[i], y_test[i])\n",
    "    ax_im.set_axis_off()\n",
    "    ax_im.set_title('{}[{}]; gold label {}'.format(\n",
    "        'train' if is_train else 'test', i, y\n",
    "    ))\n",
    "    ax_im.imshow(x, cmap='gray')\n",
    "    \n",
    "    ax_pred.clear()\n",
    "    probas = model.predict(x[None, ...])[0]\n",
    "    ax_pred.set_xticks(np.arange(len(probas)))\n",
    "    ax_pred.set_ylim(0, 1)\n",
    "    ax_pred.set_title('predicted {} ({:.3f})'.format(\n",
    "        np.argmax(probas), np.max(probas)\n",
    "    ))\n",
    "    ax_pred.bar(np.arange(len(probas)), probas)\n",
    "\n",
    "show_example(0, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)  # random as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(0, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## TF basics concepts ##\n",
    "- library for numerical computation\n",
    "    - with emphasis on numerical optimization for the purpose of machine learning\n",
    "- supports transparent GPU accelerated computation (in properly set environment)\n",
    "- well maintained (open-source + actively developed for internal use by Google)\n",
    "\n",
    "### tf.Graph ###\n",
    "- computational **graph** (~ DAG and is treated that way)\n",
    "- [more ...](https://www.tensorflow.org/guide/graphs)\n",
    "\n",
    "- #### tf.Operation ####\n",
    "    - **nodes** of the graph\n",
    "    - input tensors -> output tensors\n",
    "    \n",
    "- #### tf.Tensor ####\n",
    "    - **edges**\n",
    "    - rank, shape, dtype\n",
    "    - serve as inputs - arguments of operation to be constructed\n",
    "    - serve as ouputs - results of operation construction\n",
    "    - plain descriptors without the actual values\n",
    "    - [more ...](https://www.tensorflow.org/guide/tensors)\n",
    "\n",
    "### tf.Session ###\n",
    "- runtime environment for a graph\n",
    "- resource **manager** (memmory management for values associated to tensors)\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(6)     # to which graph the operations belong to?\n",
    "b = tf.constant(7)\n",
    "c = tf.multiply(a, b)\n",
    "\n",
    "with tf.Session():     # which graph the session manages?\n",
    "    result = c.eval()\n",
    "    print(result)\n",
    "    \n",
    "# => implicitly we are working with default graph (one is created by TF on import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, result  # as expected, variables `a`, `b` and `c` contain tensor descriptors, not the actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():                   # explicit control of graph context\n",
    "    a = tf.constant(6)\n",
    "    b = tf.constant(7)\n",
    "\n",
    "    c = tf.multiply(a, b)\n",
    "\n",
    "with tf.Session(graph=graph) as sess:  # explicit control of graph to be managed\n",
    "    result = c.eval(session=sess)      # explicit control of runtime environment for computation\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.Session() as sess:      # session allows for changes of underlying graph\n",
    "        a = tf.constant(6)\n",
    "        b = tf.constant(7)\n",
    "        c = tf.multiply(a, b)\n",
    "\n",
    "        result = c.eval()\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    a = tf.constant(6)\n",
    "    b = tf.constant(7)\n",
    "    c = a * b\n",
    "\n",
    "    with tf.Session():\n",
    "        result = c.eval()\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lessons learned ###\n",
    "- `tf.Graph.as_default()` context manager sets given graph to be the default one\n",
    "    - operations created in this context belong to this graph\n",
    "    - sessions created in this context manage this graph\n",
    "    - context can be re-entered\n",
    "- `tf.Session` manages a given graph (implicitly default one)\n",
    "    - cannot be reopened - its lifetime is `init -> close`\n",
    "    - managed graph can be modified during its lifetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "**Note:** tensor is just an edge in the graph, once its value is computed, it remains the same through the whole run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    vec = tf.random_uniform(shape=[])\n",
    "    rand_1 = vec + 1\n",
    "    rand_2 = vec + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    print(rand_1.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    print(rand_2.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    print(sess.run((rand_1, rand_2)))  # sess.run for joint evaluation of multiple tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### tf.placeholder ###\n",
    "- inputs/parameters of the computation\n",
    "- passed to session on run (via feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    a = tf.placeholder(tf.int32)\n",
    "    b = tf.placeholder(tf.int32)\n",
    "    c = tf.multiply(a, b)\n",
    "        \n",
    "with tf.Session(graph=graph) as sess:\n",
    "    print('(a={}, b={}) -> c={}'.format(*sess.run((a, b, c), feed_dict={a: 6, b: 7})))\n",
    "    print('(a={}, b={}) -> c={}'.format(*sess.run((a, b, c), feed_dict={a: 6, b: 111})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    print('(a={}, b={}, c={}) -> c={}'.format(*sess.run((a, b, c, c), feed_dict={a: 6, b: 7, c: 13})))\n",
    "\n",
    "# any tensor can be fed, and its value is not computed (as there is no reason for it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph):\n",
    "    c.eval()\n",
    "    \n",
    "# all predecessors of value we are trying to obtain must be fed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## kNN classifier ##\n",
    "Knowing the basics of TF we will implement k-NearestNeighbours and compare the performance of various implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import mode\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "class NumpyKNN:\n",
    "    def __init__(self, k, metric='cosine'):\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "    \n",
    "    def _preprocess_data(self, x_data):\n",
    "        x_data = x_data.copy()\n",
    "        return x_data.reshape(len(x_data), -1)\n",
    "    \n",
    "    def fit(self, x_train, y_train):\n",
    "        self.x_train = self._preprocess_data(x_train)\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def predict_batch(self, x_batch):\n",
    "        x_batch = self._preprocess_data(x_batch)\n",
    "        dists = cdist(self.x_train, x_batch, metric=self.metric)\n",
    "        \n",
    "        neighbours_idxs = np.argpartition(dists, self.k, axis=0)[:self.k]\n",
    "        neighbours_y = self.y_train[neighbours_idxs]\n",
    "        choices, counts = mode(neighbours_y, axis=0)\n",
    "        \n",
    "        return choices, counts / self.k\n",
    "    \n",
    "    def predict(self, x_data, batch_size=64):\n",
    "        y_data = np.empty(shape=len(x_data), dtype=np.uint8)\n",
    "        for begin_i in tqdm(range(0, len(x_data), batch_size)):\n",
    "            end_i = begin_i + batch_size\n",
    "            y_data[begin_i:end_i] = self.predict_batch(x_data[begin_i:end_i])[0]\n",
    "        return y_data\n",
    "\n",
    "    def evaluate(self, x_test, y_test, batch_size=64):\n",
    "        y_pred = self.predict(x_test, batch_size=batch_size)\n",
    "        return np.mean(y_test == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN = NumpyKNN(3)\n",
    "kNN.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN.evaluate(x_test, y_test)\n",
    "\n",
    "# ~5 min to test 10000 test examples against 60000 train examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "class FastNumpyKNN:\n",
    "    def __init__(self, k, metric='cosine'):\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "    \n",
    "    def _preprocess_data(self, x_data):\n",
    "        x_data = x_data.copy()\n",
    "        x_flat = x_data.reshape(len(x_data), -1)\n",
    "        x_norm2 = np.square(x_flat).sum(axis=-1)\n",
    "        if self.metric == 'cosine':\n",
    "            x_flat /= np.sqrt(x_norm2)[:, None]\n",
    "        elif self.metric == 'euclid':\n",
    "            pass\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        return x_flat, x_norm2\n",
    "    \n",
    "    def fit(self, x_train, y_train):\n",
    "        self.x_train, self.x_train_norm2 = self._preprocess_data(x_train)\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def predict_batch(self, x_batch):\n",
    "        x_batch, x_batch_norm2 = self._preprocess_data(x_batch)\n",
    "        \n",
    "        pairwise_dot = np.matmul(self.x_train, x_batch.T)\n",
    "        if self.metric == 'cosine':\n",
    "            dists = 1 - pairwise_dot\n",
    "        elif self.metric == 'euclid':\n",
    "            dists = self.x_train_norm2[:, None] - 2 * pairwise_dot\n",
    "        \n",
    "        neighbours_idxs = np.argpartition(dists, self.k, axis=0)[:self.k]\n",
    "        neighbours_y = self.y_train[neighbours_idxs]\n",
    "        choices, counts = mode(neighbours_y, axis=0)\n",
    "        \n",
    "        return choices, counts / self.k\n",
    "    \n",
    "    def predict(self, x_data, batch_size=64):\n",
    "        batch_size = len(x_data) if (batch_size is None) else batch_size\n",
    "        y_data = np.empty(shape=len(x_data), dtype=np.uint8)\n",
    "        for begin_i in tqdm(range(0, len(x_data), batch_size)):\n",
    "            end_i = begin_i + batch_size\n",
    "            y_data[begin_i:end_i] = self.predict_batch(x_data[begin_i:end_i])[0]\n",
    "        return y_data\n",
    "\n",
    "    def evaluate(self, x_test, y_test, batch_size=64):\n",
    "        y_pred = self.predict(x_test, batch_size=batch_size)\n",
    "        return np.mean(y_test == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_kNN = FastNumpyKNN(3, metric='cosine')\n",
    "fast_kNN.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_kNN.evaluate(x_test, y_test, batch_size=64)\n",
    "\n",
    "# ~1 min -> 5 times speedup compared to naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del fast_kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "sklearn_kNN = KNeighborsClassifier(n_neighbors=3, metric='cosine', n_jobs=-1)\n",
    "sklearn_kNN.fit(x_train.reshape(len(x_train), -1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "x_flat = x_test.reshape(len(x_test), -1)\n",
    "y_data = np.empty(shape=len(x_test), dtype=np.uint8)\n",
    "for begin_i in tqdm(range(0, len(x_test), batch_size)):\n",
    "    end_i = begin_i + batch_size\n",
    "    y_data[begin_i:end_i] = sklearn_kNN.predict(x_flat[begin_i:end_i])\n",
    "print((y_test == y_data).mean())\n",
    "\n",
    "# ~1 min => comparable to fast numpy implementation but not that customizable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sklearn_kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.stats import mode\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "\n",
    "class TfKNN:\n",
    "    def __init__(self, k, metric='cosine'):\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "        self.graph = tf.Graph()  # define TensorFlow resources\n",
    "        self.session = tf.Session(graph=self.graph)\n",
    "        \n",
    "    def __del__(self):  # handle releasing resources\n",
    "        self.session.close()\n",
    "\n",
    "    def fit(self, x_train_np, y_train_np):\n",
    "        # we are going to build the inference graph\n",
    "        # - input - batch to be predicted\n",
    "        # - preprocessing - normalization, norm computation\n",
    "        # - core - similarity computation\n",
    "\n",
    "        with self.graph.as_default():\n",
    "            # definition of inputs\n",
    "            self.x_tf = tf.placeholder(dtype=tf.float32, shape=((None,) + x_train_np.shape[1:]), name='x_data')\n",
    "            \n",
    "            # definition of preprocessing of data\n",
    "            x_preprocessed_tf = tf.reshape(self.x_tf, shape=(tf.shape(self.x_tf)[0], -1))\n",
    "            x_norm2_tf = tf.reduce_sum(tf.square(x_preprocessed_tf), axis=-1, keepdims=True)\n",
    "            if self.metric == 'cosine':\n",
    "                x_preprocessed_tf = x_preprocessed_tf / tf.sqrt(x_norm2_tf)\n",
    "            elif self.metric == 'euclid':\n",
    "                pass\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            \n",
    "            # actual preprocessing of training data using just defined preprocessing operations\n",
    "            x_train_prep_np, x_train_norm2_np = self.session.run(\n",
    "                (x_preprocessed_tf, x_norm2_tf),\n",
    "                feed_dict={self.x_tf: x_train_np}\n",
    "            )\n",
    "            \n",
    "            # embedding of preprocessed training data as constants to TF graph\n",
    "            x_train_tf = tf.constant(x_train_prep_np, dtype=tf.float32, name='x_train')\n",
    "            x_train_norm2_tf = tf.constant(x_train_norm2_np, dtype=tf.float32, name='x_train_norm2')\n",
    "            \n",
    "            # definition of knn lookup\n",
    "            pairwise_dot_tf = tf.matmul(x_train_tf, tf.transpose(x_preprocessed_tf))\n",
    "            if self.metric == 'cosine':\n",
    "                dists_tf = 1 - pairwise_dot_tf\n",
    "            elif self.metric == 'euclid':\n",
    "                dists_tf = x_train_norm2_tf - 2 * pairwise_dot_tf\n",
    "            \n",
    "            # result of TF computation - indices of neighbours (the expensive part of computation)\n",
    "            self.neighbours_idxs_tf = tf.transpose(tf.math.top_k(- tf.transpose(dists_tf), self.k, sorted=False)[1])\n",
    "            \n",
    "            self.y_train_np = y_train_np\n",
    "            \n",
    "            # force lazy loaded structures to be load (just for convenience)\n",
    "            self.session.run(self.neighbours_idxs_tf, feed_dict={self.x_tf: x_train_np[:1]})\n",
    "    \n",
    "    def predict_batch(self, x_batch_np):\n",
    "        neighbours_idxs_np = self.session.run(self.neighbours_idxs_tf, feed_dict={self.x_tf: x_batch_np})\n",
    "        neighbours_y_np = self.y_train_np[neighbours_idxs_np]\n",
    "        choices_np, counts_np = mode(neighbours_y_np, axis=0)\n",
    "        \n",
    "        return choices_np, counts_np / self.k\n",
    "    \n",
    "    def predict(self, x_data, batch_size=64):\n",
    "        batch_size = len(x_data) if (batch_size is None) else batch_size\n",
    "        y_data = np.empty(shape=len(x_data), dtype=np.uint8)\n",
    "        for begin_i in tqdm(range(0, len(x_data), batch_size)):\n",
    "            end_i = begin_i + batch_size\n",
    "            y_data[begin_i:end_i] = self.predict_batch(x_data[begin_i:end_i])[0]\n",
    "        return y_data\n",
    "\n",
    "    def evaluate(self, x_test, y_test, batch_size=64):\n",
    "        y_pred = self.predict(x_test, batch_size=batch_size)\n",
    "        return np.mean(y_test == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_kNN = TfKNN(3, metric='cosine')\n",
    "tf_kNN.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_kNN.evaluate(x_test, y_test)\n",
    "\n",
    "# CPU ~ 15 sec => 4x speedup compared to sklearn/fast numpy, 20x speedup overall\n",
    "# GPU ~ 4 sec => ~15x speedup compared to sklearn/fast numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tf_kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### tf.Variable ####\n",
    "- can be reassigned new value\n",
    "- lifecycle\n",
    "    - needs to be initialized\n",
    "    - keeps its value between session runs\n",
    "    - is deallocated when session closes\n",
    "- an operation with behaviour of tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "        x = tf.placeholder(tf.int32, shape=(), name=\"x\")\n",
    "        acc = tf.get_variable(\"acc\", shape=(), dtype=tf.int32, initializer=tf.zeros_initializer())\n",
    "        add_x = acc.assign_add(x)\n",
    "\n",
    "        tf.global_variables_initializer().run()\n",
    "        print(acc.eval())\n",
    "        for i in range(1, 11):\n",
    "            print(\"+ {:2d}:\".format(i), add_x.eval(feed_dict={x: i}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.stats import mode\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "\n",
    "class TfOnlineKNN:\n",
    "    def __init__(self, k, metric='cosine'):\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "        self.graph = tf.Graph()\n",
    "        self.session = tf.Session(graph=self.graph)\n",
    "        self._is_built = False\n",
    "    \n",
    "    def __del__(self):  # handle releasing resources\n",
    "        self.session.close()\n",
    "\n",
    "    def _build(self, ex_shape):\n",
    "        if self._is_built:\n",
    "            return\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "            # definition of placeholders\n",
    "            self.x_tf = tf.placeholder(dtype=tf.float32, shape=((None,) + tuple(ex_shape)), name='x_data')\n",
    "            \n",
    "            # definition of preprocessing of data\n",
    "            x_preprocessed_tf = tf.reshape(self.x_tf, shape=(tf.shape(self.x_tf)[0], -1))\n",
    "            x_norm2_tf = tf.reduce_sum(tf.square(x_preprocessed_tf), axis=-1, keepdims=True)\n",
    "            if self.metric == 'cosine':\n",
    "                x_preprocessed_tf = x_preprocessed_tf / tf.sqrt(x_norm2_tf)\n",
    "            elif self.metric == 'euclid':\n",
    "                pass\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            \n",
    "            # definition of reference data (train) as mutable variables\n",
    "            x_train_tf = tf.get_variable(\"x_train\", shape=(0, np.product(ex_shape)), dtype=tf.float32, trainable=False, validate_shape=False)\n",
    "            x_train_norm2_tf = tf.get_variable(\"x_train_norm2\", shape=(0, 1), dtype=tf.float32, trainable=False, validate_shape=False)\n",
    "            \n",
    "            self.enlarge_train = tf.group((\n",
    "                tf.assign(x_train_tf, tf.concat((x_train_tf.read_value(), x_preprocessed_tf), axis=0), validate_shape=False),\n",
    "                tf.assign(x_train_norm2_tf, tf.concat((x_train_norm2_tf.read_value(), x_norm2_tf), axis=0), validate_shape=False)\n",
    "            ))\n",
    "            \n",
    "            # definition of knn lookup\n",
    "            pairwise_dot_tf = tf.matmul(x_train_tf, tf.transpose(x_preprocessed_tf))\n",
    "            if self.metric == 'cosine':\n",
    "                dists_tf = 1 - pairwise_dot_tf\n",
    "            elif self.metric == 'euclid':\n",
    "                dists_tf = x_train_norm2_tf - 2 * pairwise_dot_tf\n",
    "            \n",
    "            self.neighbours_idxs_tf = tf.transpose(tf.math.top_k(- tf.transpose(dists_tf), self.k, sorted=False)[1])\n",
    "            \n",
    "            # initialize variables\n",
    "            self.session.run(tf.global_variables_initializer())\n",
    "\n",
    "        self._is_built = True\n",
    "        \n",
    "    def fit_append(self, x_train_np, y_train_np):\n",
    "        self._build(x_train_np.shape[1:])\n",
    "        self.session.run(self.enlarge_train, feed_dict={self.x_tf: x_train_np})\n",
    "        self.y_train_np = np.concatenate((self.y_train_np, y_train_np)) if hasattr(self, \"y_train_np\") else y_train_np\n",
    "    \n",
    "    def predict_batch(self, x_batch_np):\n",
    "        neighbours_idxs_np = self.session.run(self.neighbours_idxs_tf, feed_dict={self.x_tf: x_batch_np})\n",
    "        neighbours_y_np = self.y_train_np[neighbours_idxs_np]\n",
    "        choices_np, counts_np = mode(neighbours_y_np, axis=0)\n",
    "        \n",
    "        return choices_np, counts_np / self.k\n",
    "\n",
    "    def predict(self, x_data, batch_size=64):\n",
    "        batch_size = len(x_data) if (batch_size is None) else batch_size\n",
    "        y_data = np.empty(shape=len(x_data), dtype=np.uint8)\n",
    "        for begin_i in tqdm(range(0, len(x_data), batch_size), leave=False):\n",
    "            end_i = begin_i + batch_size\n",
    "            y_data[begin_i:end_i] = self.predict_batch(x_data[begin_i:end_i])[0]\n",
    "        return y_data\n",
    "\n",
    "    def evaluate(self, x_test, y_test, batch_size=64):\n",
    "        y_pred = self.predict(x_test, batch_size=batch_size)\n",
    "        return np.mean(y_test == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfo_kNN = TfOnlineKNN(3, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grow_size = 500\n",
    "for begin in range(0, 10000, grow_size):\n",
    "    end = begin + grow_size\n",
    "    tfo_kNN.fit_append(x_train[begin:end], y_train[begin:end])\n",
    "    print(\"{:5d} samples:\".format(end), tfo_kNN.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
