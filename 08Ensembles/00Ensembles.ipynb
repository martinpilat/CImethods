{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Ansámbly\n",
    "\n",
    "##Teoretický základ\n",
    "\n",
    "__silné__ modely (ituitivně, schopné naučit se úlohu velmi dobře), formálně se definují pomocí  PAC (probably approximately correct) neboli silné naučitelnosti\n",
    "\n",
    "__slabé__ modely (intuitivně, schopné naučit se úlohu jen o něco málo lépe než náhodný model), definují se pomocí slabé naučitelnosti. \n",
    "\n",
    "Zřejmě, silná naučitelnst implikuje slabou naučitelnost.\n",
    "\n",
    "Neintuitivní výsledek je, že silná a slabá naučitelnost je ekvivalentní - princip důkazu je vlastně _boosting_\n",
    "\n",
    "- vytvoření (více) nových modelů dat na základě změněných dat (resampling, vážení)\n",
    "- kombinace výstupů modelů - průměrování, hlasování (vážené)\n",
    "\n",
    "__bias__ - neschopnost modelu naučit se dobře daná data\n",
    "\n",
    "__variance__ - model je citlivý na konkrétní data \n",
    "\n",
    "nízký bias znamená často velkou varianci\n",
    "\n",
    "bagging redukuje varianci\n",
    "\n",
    "boosting redukuje bias\n",
    "\n",
    "Z teorie (a praxe) vyplývá:\n",
    "\n",
    "- kombinací slabých modelů dokážeme vyrobit silnější model\n",
    "- \n",
    "\n",
    "\n",
    "##Bagging\n",
    "\n",
    "\"bootstrap aggregating\"\n",
    "\n",
    "__bagging__ : vzory z dat jsou vybírány náhodně s nahrazením (bootstrap)\n",
    "\n",
    "__pasting__ : náhodné disjunktní podmnožiny dat\n",
    "\n",
    "__random subspaces__ : náhodné podmnožiny příznaků\n",
    " \n",
    "__random patches__ : náhodné podmnožiny příznaků i dat\n",
    " \n",
    " \n",
    "náhodné lesy - bagging a podprostory klasifikačních stromů \n",
    "\n",
    "\n",
    "\n",
    "##Boosting\n",
    "\n",
    "- jednoduchý model na všech datech s váhou $1/n$\n",
    "\n",
    "- druhý model na vážených datech dle výsledků prvního modelu $E<0.5$\n",
    "\n",
    "špatně klasifikované, váhy vynásobíme: $1/2E$ \n",
    "dobře klasifikované, váhy vynásobíme: $1/2(1-E)$\n",
    "\n",
    "- ...\n",
    "\n",
    "- modely jsou váženy $w_t = 1/2\\ln{\\frac{1-E_t}{E_t}}$\n",
    "\n",
    "AdaBoost\n",
    "\n",
    "##Stacking\n",
    "\n",
    "- kombinace moelů pomocí lineárního (meta-)modelu\n",
    "- jiné meta-modely\n",
    "- hybridní ansámbly\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Příklad: Hlasování většinové (hard) vs. vážené (soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90 (+/- 0.05) [Logistic Regression]\n",
      "Accuracy: 0.93 (+/- 0.05) [Random Forest]\n",
      "Accuracy: 0.91 (+/- 0.04) [naive Bayes]\n",
      "Accuracy: 0.95 (+/- 0.05) [Hard voting Ens]\n",
      "Accuracy: 0.95 (+/- 0.04) [Soft voting Ens]\n"
     ]
    }
   ],
   "source": [
    ">>> from sklearn import datasets\n",
    ">>> from sklearn import cross_validation\n",
    ">>> from sklearn.linear_model import LogisticRegression\n",
    ">>> from sklearn.naive_bayes import GaussianNB\n",
    ">>> from sklearn.ensemble import RandomForestClassifier\n",
    ">>> from sklearn.ensemble import VotingClassifier\n",
    "\n",
    ">>> iris = datasets.load_iris()\n",
    ">>> X, y = iris.data[:, 1:3], iris.target\n",
    "\n",
    ">>> clf1 = LogisticRegression(random_state=1)\n",
    ">>> clf2 = RandomForestClassifier(random_state=1)\n",
    ">>> clf3 = GaussianNB()\n",
    "\n",
    ">>> eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    ">>> eclf2 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft')\n",
    ">>> for clf, label in zip([clf1, clf2, clf3, eclf, eclf2], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Hard voting Ens', 'Soft voting Ens']):\n",
    "...     scores = cross_validation.cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "...     print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
